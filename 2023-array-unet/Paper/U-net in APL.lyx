#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass acmart
\begin_preamble

\usepackage{dblfloatfix}
\end_preamble
\options format=sigplan,screen,balance
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding utf8
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "APL385 Unicode"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts true
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype true
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 10
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine natbib
\cite_engine_type authoryear
\biblio_style ACM-Reference-Format
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 2
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Set Copyright
rightsretained
\end_layout

\begin_layout ACM DOI
10.1145/3589246.3595371
\end_layout

\begin_layout ACM Year
2023
\end_layout

\begin_layout Copyright Year
2023
\end_layout

\begin_layout ACM Submission ID
pldiws23arraymain-p5-p
\end_layout

\begin_layout ACM ISBN
979-8-4007-0169-6/23/06
\end_layout

\begin_layout ACM Conference
\begin_inset Argument 1
status open

\begin_layout Plain Layout
ARRAY '23
\end_layout

\end_inset


\begin_inset Argument 2
status open

\begin_layout Plain Layout
Proceedings of the 9th ACM SIGPLAN International Workshop on Libraries,
 Languages and Compilers for Array Programming
\end_layout

\end_inset


\begin_inset Argument 3
status open

\begin_layout Plain Layout
June 18, 2023
\end_layout

\end_inset


\begin_inset Argument 4
status open

\begin_layout Plain Layout
Orlando, FL, USA
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
acmBooktitle{Proceedings of the 9th ACM SIGPLAN International Workshop on
 Libraries, Languages and Compilers for Array Programming (ARRAY '23), June
 18, 2023, Orlando, FL, USA}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
acmPrice{}
\end_layout

\end_inset


\end_layout

\begin_layout Received
2023-03-31
\end_layout

\begin_layout Received
\begin_inset Argument 1
status open

\begin_layout Plain Layout
accepted
\end_layout

\end_inset

2023-04-21
\end_layout

\begin_layout CCSXML

<ccs2012>
\end_layout

\begin_layout CCSXML

  <concept>
\end_layout

\begin_layout CCSXML

    <concept_id>10011007.10011006.10011008.10011009.10010175</concept_id>
\end_layout

\begin_layout CCSXML

    <concept_desc>Software and its engineering~Parallel programming languages</c
oncept_desc> 
\end_layout

\begin_layout CCSXML

    <concept_significance>500</concept_significance>
\end_layout

\begin_layout CCSXML

  </concept>
\end_layout

\begin_layout CCSXML

  <concept>
\end_layout

\begin_layout CCSXML

    <concept_id>10011007.10011006.10011041.10011048</concept_id>
\end_layout

\begin_layout CCSXML

    <concept_desc>Software and its engineering~Runtime environments</concept_des
c>
\end_layout

\begin_layout CCSXML

    <concept_significance>500</concept_significance>
\end_layout

\begin_layout CCSXML

  </concept>
\end_layout

\begin_layout CCSXML

</ccs2012>
\end_layout

\begin_layout CCS Description

Software and its engineering~Parallel programming languages
\end_layout

\begin_layout CCS Description

Software and its engineering~Runtime environments
\end_layout

\begin_layout Keywords
APL, Compilers, Neural Networks, Machine Learning, GPU, Co-dfns
\end_layout

\begin_layout Title
U-Net CNN in APL
\end_layout

\begin_layout Subtitle
Exploring Zero-Framework, Zero-Library Machine Learning
\end_layout

\begin_layout Author
Aaron W.
 Hsu
\end_layout

\begin_layout Email
aaron@dyalog.com
\end_layout

\begin_layout ORCID
0000-0001-9292-7783
\end_layout

\begin_layout Affiliation
\begin_inset Flex Institution
status open

\begin_layout Plain Layout
Dyalog, Ltd.
\end_layout

\end_inset


\begin_inset Flex City
status open

\begin_layout Plain Layout
Bloomington, IN
\end_layout

\end_inset


\begin_inset Flex Country
status open

\begin_layout Plain Layout
United States
\end_layout

\end_inset


\end_layout

\begin_layout Author
Rodrigo Girão Serrão
\end_layout

\begin_layout Email
rodrigo@dyalog.com
\end_layout

\begin_layout ORCID
0009-0009-3361-3835
\end_layout

\begin_layout Affiliation
\begin_inset Flex Institution
status open

\begin_layout Plain Layout
Dyalog, Ltd.
\end_layout

\end_inset


\begin_inset Flex City
status open

\begin_layout Plain Layout
Bramley
\end_layout

\end_inset


\begin_inset Flex Country
status open

\begin_layout Plain Layout
United Kingdom
\end_layout

\end_inset


\end_layout

\begin_layout Abstract
The APL notation would appear to be a clear match for convolutional neural
 networks, but traditional implementations of APL have lagged behind the
 performance of highly tuned, specialized frameworks designed to execute
 CNNs on the GPU.
 Moreover, most demonstrations of APL for neural networking have involved
 relatively small examples.
 We explore a more complex example in the U-net architecture and utilize
 a modern APL compiler with GPU support, Co-dfns, to compare the state of
 the art of APL against the current crop of specialized neural network framework
s in the form of PyTorch.
 We compare performance as well as the language design of APL for neural
 network programming and the clarity and transparency of the resulting code.
 
\end_layout

\begin_layout Abstract
We found that the complete 
\begin_inset Quotes eld
\end_inset

from scratch
\begin_inset Quotes erd
\end_inset

 APL source was on par with the complexity of the PyTorch reference implementati
on, albeit more foreign, while being more concise and complete.
 We also found that when compiled with Co-dfns, despite the naïve implementation
 both of Co-dfns and our own code, performance on the GPU and the CPU were
 within a factor of 2.2 - 2.4 times that of the PyTorch implementation.
 We believe this suggests significant avenues of future exploration for
 machine learning language design, pedagogy, and implementation, both inside
 and outside of the APL community.
 
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Specialized machine learning frameworks dominate present deep learning applicati
ons.
 A wide number of highly specialized, optimized libraries exist.
 These systems are more complex than typical libraries and are better thought
 of as domain-specific languages (DSLs).
 While these libraries bolster the current machine learning explosion, because
 of their highly specialized nature, users tend to become specialists around
 a very specific framework for computation.
 This creates a sharp wall that impedes skills transference, where experts
 can use frameworks effectively but may be under-prepared to handle situations
 that benefit from broader or more flexible skill-sets.
\begin_inset Foot
status open

\begin_layout Plain Layout
To someone who only has a hammer, everything looks like a nail.
\end_layout

\end_inset

 This specialization makes sense in the context of traditional programming,
 where simple networks are accessible, but tedious, while non-trivial ML
 architectures quickly strain the performance and usability of a 
\begin_inset Quotes eld
\end_inset

from scratch
\begin_inset Quotes erd
\end_inset

 implementation.
 This creates a sharp contrast between simple systems programmed 
\begin_inset Quotes eld
\end_inset

by hand
\begin_inset Quotes erd
\end_inset

 and opaque, complex frameworks that work as inflexible black boxes.
 A lack of profound and intuitive understanding of the underlying mechanics
 of deep learning systems fosters a type of 
\begin_inset Quotes eld
\end_inset

programming by knob turning
\begin_inset Quotes erd
\end_inset

 where networks are programmed via trial and error rather than intentionality,
 further exacerbating the danger of unintended consequences, already an
 inherent difficulty in statistical ML 
\begin_inset CommandInset citation
LatexCommand citep
key "domingos2012few"
literal "false"

\end_inset

.
 Machine learning frameworks are often highly vendor-specific; even vendor-neutr
al systems encode greater specificity than warranted for long-running code.
 This demands higher levels of programmer investment in system maintenance
 over a product lifetime.
 Despite this, specialist frameworks prove highly effective, in part because
 of the performance demands of ML.
 However, in recent years, reemerging general-purpose array programming
 languages have presented an alternative potential direction.
 Such languages were popular during early neural network programming in
 the 20th century 
\begin_inset CommandInset citation
LatexCommand citep
key "alfonseca-1990-aplnn"
literal "false"

\end_inset

, but performance of then-current hardware prevented further development.
\end_layout

\begin_layout Standard
APL, a general-purpose array programming language, created by Kenneth Iverson
 as an improved mathematical notation 
\begin_inset CommandInset citation
LatexCommand citep
key "apl"
literal "false"

\end_inset

, has risen in popularity over the past decades, in part because of the
 renewed interest in parallel computation and a wider acceptance of the
 use of a variety of programming languages.
 Recently, new research into APL as a machine learning language has begun.
 APL's origins in education and its reputation for direct algorithmic expression
 
\begin_inset CommandInset citation
LatexCommand citep
key "knuth1993computer,knuth2007computer"
literal "false"

\end_inset

 address some of the above concerns around general-purpose languages and
 ML.
 As a linguistically stable language that is both high performance and high
 level 
\begin_inset CommandInset citation
LatexCommand citep
key "hsu2019data"
literal "false"

\end_inset

, it is suitable for long lived code as well as rapid prototyping, and the
 data-parallel by default semantics suggests obvious applications to GPU
 programming.
 While these advantages might recommend APL for machine learning, the majority
 of implementations have run on the CPU only, usually via interpreter.
 While challenging to compile, recent innovations to the language (particularly
 those with a functional programming focus) make compilation more tractable,
 and the Co-dfns compiler now exists as an APL implementation with native
 GPU support 
\begin_inset CommandInset citation
LatexCommand citep
key "hsu2019data"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Standard
Given the available APL technology and the paucity of existing research
 on modern ML in APL, we explored APL as a ML language in terms of language
 design and runtime performance by implementing and benchmarking the U-net
 convolutional neural network 
\begin_inset CommandInset citation
LatexCommand citep
key "unet"
literal "false"

\end_inset

.
 This is a popular image segmentation architecture with a particularly interesti
ng U-shaped design.
 It makes use of a range of popular CNN vocabularies and functions while
 having a clear, non-trivial architecture.
 This makes an ideal candidate for exploring APL's capabilities.
\end_layout

\begin_layout Standard
We make the following contributions:
\end_layout

\begin_layout Itemize
A from scratch implementation of the U-net convolutional neural network
 in APL
\end_layout

\begin_layout Itemize
Our U-net implementation is exceptionally simple, concise, transparent,
 and direct
\end_layout

\begin_layout Itemize
Our implementation consists of pure APL and no dependencies, frameworks,
 libraries, or other supporting code
\end_layout

\begin_layout Itemize
Performance results of two modern APL implementations, one compiled and
 the other interpreted, on CPU and GPU hardware against a reference PyTorch
 implementation for U-net
\end_layout

\begin_layout Section
Background
\end_layout

\begin_layout Subsection
Convolutional Neural Networks
\end_layout

\begin_layout Standard
The experiment this paper uses to produce its benchmarks is the reproduction
 of a well-known convolutional neural network architecture.
 The use of CNNs in machine learning was widely popularized with the publication
 of a paper 
\begin_inset CommandInset citation
LatexCommand citep
key "cnns-imagenet"
literal "false"

\end_inset

 that used CNNs to achieve state-of-the-art performance in labeling pictures
 of the ImageNet 
\begin_inset CommandInset citation
LatexCommand citep
key "imagenet"
literal "false"

\end_inset

 challenge.
 However, a prominent paper from 1998 
\begin_inset CommandInset citation
LatexCommand citep
key "cnns-lecun-doc-recognition"
literal "false"

\end_inset

 shows that the modern use of CNNs can be dated farther back.
\end_layout

\begin_layout Standard
The use of convolutional neural networks, as we know them today, builds
 on top of the convolutional layer 
\begin_inset CommandInset citation
LatexCommand citep
key "intro-to-cnn"
literal "false"

\end_inset

.
 Convolutional layers receive 3-dimensional tensors as input and produce
 three-dimensional tensors as output.
 These inputs have a fixed number of channels
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Quotes eld
\end_inset

channel
\begin_inset Quotes erd
\end_inset

 typically refers to the leading dimension of these inputs/outputs, a nomenclatu
re that is derived from the fact that CNNs were popularized in the context
 of image processing.
\end_layout

\end_inset

 
\begin_inset Formula $n_{in}$
\end_inset

 which are then transformed into 
\begin_inset Formula $n_{out}$
\end_inset

 channels through means of discrete convolutions with a total of 
\begin_inset Formula $n_{in}\times n_{out}$
\end_inset

 kernels, the learnable parameters of the convolutional layer.
 One of the advantages of CNNs is that, although the total number of kernels
 
\begin_inset Formula $n_{in}\times n_{out}$
\end_inset

 depends on the number of input and output channels, the sizes of the kernels
 are independent of the size of the other two dimensions of the inputs.
 Despite the fact that the main dynamics of a convolutional layer is governed
 by discrete convolution with the learnable kernels, the exact behavior
 of a convolutional layer depends on layer parameters like the padding and
 the stride used 
\begin_inset CommandInset citation
LatexCommand citep
key "conv-arithmetic-guide"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Since CNNs were primarily used in image recognition-related tasks, convolutional
 layers were often paired with pooling layers to ease the recognition of
 features over small neighborhoods 
\begin_inset CommandInset citation
LatexCommand citep
key "pooling"
literal "false"

\end_inset

 by aggregating low-level information to recognize larger features of interest,
 with the rationale that typical image features (e.g., the recognition or
 segmentation of objects, or image labeling) consist of regions of pixels
 and not individual pixels.
\end_layout

\begin_layout Subsection
Original U-Net Architecture
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename u-net-architecture.png
	width 60page%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Original u-net architecture, as seen in the original paper 
\begin_inset CommandInset citation
LatexCommand citep
key "unet"
literal "false"

\end_inset

.
 Arrows represent operations between the multi-channel feature maps represented
 by the rectangles.
 The number on top of each rectangle is its number of channels and the numbers
 in the lower-left corner are the 
\begin_inset Formula $x$
\end_inset

 and 
\begin_inset Formula $y$
\end_inset

 dimensions of the feature maps.
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "fig:unet-architecture"

\end_inset


\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand citet
key "unet"
literal "false"

\end_inset

 introduced the U-net architecture, a novel CNN architecture that won several
 biomedical image segmentation challenges.
 Since the original implementation in Caffe 
\begin_inset CommandInset citation
LatexCommand citep
key "caffe"
literal "false"

\end_inset

, others have implemented U-net in numerous other frameworks and systems
\begin_inset Foot
status open

\begin_layout Plain Layout
Numbers by 
\begin_inset CommandInset href
LatexCommand href
name "Papers with Code"
target "https://paperswithcode.com/paper/u-net-convolutional-networks-for-biomedical"
literal "false"

\end_inset

 as of March, 2022.
\end_layout

\end_inset

, including PyTorch 
\begin_inset CommandInset citation
LatexCommand citep
key "pytorch"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:unet-architecture"
plural "false"
caps "false"
noprefix "false"

\end_inset

 shows the original diagram that represents the U-net architecture 
\begin_inset CommandInset citation
LatexCommand citep
key "unet"
literal "false"

\end_inset

.
 The blue right arrows, labeled 
\begin_inset Quotes eld
\end_inset

conv 3x3, ReLU
\begin_inset Quotes erd
\end_inset

, represent unpadded convolutions with 
\begin_inset Formula $3\times3$
\end_inset

 kernels.
 After each of these convolutions, the size of the feature map decreases
 by 
\begin_inset Formula $2$
\end_inset

, from which it can be inferred that the stride 
\begin_inset CommandInset citation
LatexCommand citep
key "conv-arithmetic-guide"
literal "false"

\end_inset

 is 
\begin_inset Formula $1$
\end_inset

.
 A rectified linear unit (ReLU) 
\begin_inset CommandInset citation
LatexCommand citep
key "relu"
literal "false"

\end_inset

 activation function follows each convolution.
 After two such convolutions, max-pooling operations represented by the
 red down arrows downsample each feature map to half the size using a 
\begin_inset Formula $2\times2$
\end_inset

 region with stride 
\begin_inset Formula $2$
\end_inset

.
\begin_inset Foot
status open

\begin_layout Plain Layout
This makes the input size somewhat brittle.
 Specifically, the input dimensions must be congruent to 
\begin_inset Formula $12\mod16$
\end_inset


\end_layout

\end_inset

 After every downsampling step, the first convolution doubles the number
 of channels.
 The pattern of two convolutions (with ReLUs) followed by downsampling via
 max-pooling happens four times and makes up the contracting path of the
 network, on the left of the diagram.
\end_layout

\begin_layout Standard
After the contracting path (at the diagram bottom) completes, a corresponding
 expanding path reduces the channels while increasing the map size.
 Expansion uses unpadded 
\begin_inset Formula $3\times3$
\end_inset

 convolutions preceded by an upsampling operation (green up arrows) that
 doubles the map size while halving the channels.
 We infer that the original authors used a transposed convolution (with
 
\begin_inset Formula $2\times2$
\end_inset

 kernels) of stride 
\begin_inset Formula $2$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand citep
key "conv-arithmetic-guide"
literal "false"

\end_inset


\begin_inset Foot
status open

\begin_layout Plain Layout
See 
\begin_inset CommandInset citation
LatexCommand citep
key "up-transposed"
literal "false"

\end_inset

 for an informal discussion of this inference.
\end_layout

\end_inset

.
 Half of the channels to the initial convolution after upsampling come from
 the corresponding map on the contracting side of the architecture, as represent
ed by the gray right long arrows in the middle of the diagram.
 The copied maps are center cropped to ensure matching dimensions.
 At the end of the contracting path, a 
\begin_inset Formula $1\times1$
\end_inset

 unpadded convolution reduces the 
\begin_inset Formula $64$
\end_inset

 feature maps to 
\begin_inset Formula $2$
\end_inset

 feature maps (one per class).
\end_layout

\begin_layout Subsection
APL Notation
\end_layout

\begin_layout Standard
APL, introduced by Turing award winner Kenneth E.
 Iverson in the '60s 
\begin_inset CommandInset citation
LatexCommand citep
key "apl"
literal "false"

\end_inset

, is an executable mathematical notation 
\begin_inset CommandInset citation
LatexCommand citep
key "apl-since-78"
literal "false"

\end_inset

.
 This section introduces the basics of the notation used in this paper,
 but 
\begin_inset CommandInset citation
LatexCommand citet
key "mdapl"
literal "false"

\end_inset

 more fully describes the language.
 Online interactive systems allow for experimentation with the language
 without needing to install anything.
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://tryapl.org
\end_layout

\end_inset


\end_layout

\end_inset

 All notation used here is compatible with Dyalog APL 18.0
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://dyalog.com/
\end_layout

\end_inset


\end_layout

\end_inset

.
\end_layout

\begin_layout Subsubsection
Arrays
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Array names according to 
\emph on
rank
\emph default
.
\begin_inset CommandInset label
LatexCommand label
name "tab:rank-names"

\end_inset


\end_layout

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="7" columns="2">
<features booktabs="true" tabularvalignment="middle">
<column alignment="left" valignment="top" width="0pt">
<column alignment="left" valignment="top">
<row>
<cell alignment="left" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\emph on
Rank
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\emph on
Name
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Scalar
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Vector
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Matrix
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Cuboid
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Hypercube
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5+
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Noble
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The primary datatype of an APL system is the array.
\begin_inset Foot
status open

\begin_layout Plain Layout
Other types may exist for commercial systems, but these are not treated
 here.
\end_layout

\end_inset

 In APL, an array is an 
\begin_inset Formula $N$
\end_inset

-dimensional rectangular arrangement of one or more elements in row-major
 order according to a list of zero or more orthogonal dimensions (axes)
 called its 
\noun on
shape
\noun default
, with the number of axes called its 
\noun on
rank
\noun default
.
 Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:rank-names"
plural "false"
caps "false"
noprefix "false"

\end_inset

 gives the common names for sub-classes of arrays by rank.
 Scalars have exactly one element.
 Higher ranked, non-empty arrays contain as many elements as the product
 of its axes, while those with at least one zero length axis, called 
\noun on
empty
\noun default
 arrays, have a single element called the 
\noun on
prototype
\noun default
, or 
\noun on
fill
\noun default
, element.
 For all numeric arrays, such as those used in this paper, the fill element
 is 
\family typewriter
0
\family default
, and it is used by some primitives to extend or resize arrays to larger
 shapes.
 Indices begin at 0, rather than 1.
\begin_inset Foot
status open

\begin_layout Plain Layout
Dyalog APL defaults to 1-based indexing.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The elements of an array consist solely of other arrays, allowing APL to
 have a single, uniform datatype.
\begin_inset Foot
status open

\begin_layout Plain Layout
This historically contentious design choice will be taken for granted.
 Industrious readers may explore alternative designs elsewhere.
\end_layout

\end_inset

 To make computation meaningful, APL defines a set of scalar arrays that
 correspond to primitive values in the system, such as numbers and characters.
 Thus, when we write a number like 
\family typewriter
1
\family default
, 
\family typewriter
3.5
\family default
, or 
\family typewriter
1e¯8
\family default
, this is the scalar array corresponding to that number in the APL system.
\end_layout

\begin_layout Subsubsection
Expressions
\end_layout

\begin_layout Standard
Expressions consist of a series of literals/variables, applications, bindings,
 or assignments.
 Literal expressions describe an array.
 A single numeric value is a literal.
 Adjacent values, separated by whitespace, form a vector of those values.
 For example:
\end_layout

\begin_layout Verbatim

¯5    ⍝ Scalar negative 5
\end_layout

\begin_layout Verbatim

5 3 1 ⍝ Vector of 3 elements
\end_layout

\begin_layout Standard
Note the use of a high minus to indicate a literal negative number instead
 of 
\family typewriter
-5
\family default
, which is the application of the negate function to 
\family typewriter
5
\family default
.
\end_layout

\begin_layout Standard
Functions can be first or second order.
 First order functions, called 
\noun on
functions
\noun default
, take arrays as arguments and return a single array value as a result,
 while second order functions, called 
\noun on
operators, 
\noun default
take arrays or 
\noun on
functions
\noun default
 as arguments and return a 
\noun on
function 
\noun default
result.
 From now on, we use the term 
\noun on
function
\noun default
 to refer to first-order functions only.
 Application takes one of the following infix forms:
\end_layout

\begin_layout Verbatim

   fn ⍵  ⍝ Monadic function application
\end_layout

\begin_layout Verbatim

 ⍺ fn ⍵  ⍝ Dyadic  function application
\end_layout

\begin_layout Verbatim

⍺⍺ op    ⍝ Monadic operator application
\end_layout

\begin_layout Verbatim

⍺⍺ op ⍵⍵ ⍝ Dyadic  operator application
\end_layout

\begin_layout Standard
The terms 
\noun on
monadic
\noun default
 and 
\noun on
dyadic
\noun default
 refer to arity, not monads in the functional programming sense.
 We use 
\family typewriter
⍺
\family default
, 
\family typewriter
⍵
\family default
, 
\family typewriter
⍺⍺
\family default
, and 
\family typewriter
⍵⍵
\family default
 to refer to the left and right arguments (for function application) and
 operands (for operator application), respectively.
 Operators have higher binding precedence than functions, and operators
 always associate to the left while functions always associate to the right.
 This applies even in cases where traditional math primitives are used.
 Consider the following example, where 
\family typewriter
⌿
\family default
 is a monadic operator, and 
\family typewriter
.

\family default
 a dyadic:
\end_layout

\begin_layout Verbatim

   +.×⌿-2×3-4+3×5
\end_layout

\begin_layout Verbatim

←→ (((+.×)⌿)(-(2×(3-(4+(3×5))))))
\end_layout

\begin_layout Standard
Notice that 
\family typewriter
-
\family default
 is applied both monadically and dyadically.
 
\end_layout

\begin_layout Subsubsection
Primitives
\end_layout

\begin_layout Standard
APL is known for its primitives: built-in functions and operators assigned
 special symbols instead of the standard alphanumeric variable names given
 to user-defined values.
 The examples used in this paper are expressions of mostly primitive functions
 and operators.
\end_layout

\begin_layout Standard
The largest class of primitives are the 
\noun on
scalar functions
\noun default
, defined over a single scalar value or values and extended to all arrays
 by point-wise, also called element-wise, extension.
 The left and right arguments of a scalar function must share the same shape,
 with scalar arguments extended to the same shape as the other argument.
 Consider the following example using addition:
\end_layout

\begin_layout Verbatim

      5+1 3 7 10 ⍝ Scalar extension
\end_layout

\begin_layout Verbatim

6 8 12 15
\end_layout

\begin_layout Standard
Scalar functions return arrays the same shape as their inputs.
 The set of scalar functions used in this paper include the standard arithmetic
 functions 
\family typewriter
+
\family default
, 
\family typewriter
×
\family default
, 
\family typewriter
÷
\family default
, 
\family typewriter
-
\family default
, 
\family typewriter
⌈
\family default
 (ceiling or maximum), 
\family typewriter
⌊
\family default
 (floor/minimum), 
\family typewriter
|
\family default
 (absolute value), and 
\family typewriter
*
\family default
 (exponent), as well as the Boolean relations 
\family typewriter
<
\family default
, 
\family typewriter
≤
\family default
, 
\family typewriter
=
\family default
, 
\family typewriter
≠
\family default
, 
\family typewriter
≥
\family default
, 
\family typewriter
>
\family default
, and 
\family typewriter
~
\family default
 (not) which return 
\family typewriter
1
\family default
 for 
\noun on
true
\noun default
 and 
\family typewriter
0
\family default
 for 
\noun on
false
\noun default
.
\end_layout

\begin_layout Standard
The core primitive 
\family typewriter
⍴
\family default
 is used for the shape of an array.
 The monadic application 
\family typewriter
⍴⍵
\family default
 returns a vector of the axes of 
\family typewriter
⍵
\family default
.
 The dyadic application 
\family typewriter
⍺⍴⍵
\family default
 returns an array whose shape is 
\family typewriter
⍺
\family default
 and whose elements are taken in wrapping order from 
\family typewriter
⍵
\family default
.
 For example:
\end_layout

\begin_layout Verbatim

      3 5⍴1 2 3 4 ⍝ A 3×5 matrix
\end_layout

\begin_layout Verbatim

1 2 3 4 1
\end_layout

\begin_layout Verbatim

2 3 4 1 2
\end_layout

\begin_layout Verbatim

3 4 1 2 3
\end_layout

\begin_layout Standard
The function 
\family typewriter
≢⍵
\family default
 applied monadically returns the length of the first axis of 
\family typewriter
⍵
\family default
, that is, the first element of 
\family typewriter
⍴⍵
\family default
.
 
\end_layout

\begin_layout Verbatim

      ≢7 5 6⍴0
\end_layout

\begin_layout Verbatim

7
\end_layout

\begin_layout Standard
Thus, the rank of an array is given by 
\family typewriter
≢⍴⍵
\family default
.
\end_layout

\begin_layout Verbatim

      ≢⍴7 5 6⍴0
\end_layout

\begin_layout Verbatim

3
\end_layout

\begin_layout Standard
The expression 
\family typewriter
⍳N
\family default
 gives the natural numbers up to 
\family typewriter
N
\family default
.
\end_layout

\begin_layout Verbatim

      ⍳7
\end_layout

\begin_layout Verbatim

0 1 2 3 4 5 6
\end_layout

\begin_layout Standard
The primitives 
\family typewriter
⊖
\family default
 and 
\family typewriter
⌽
\family default
 rotate arrays along the first and last axis, respectively.
 Applied monadically, they reverse/flip an array along the appropriate axis.
 When applied dyadically, they shift an array by the specified amount.
 Thus 
\family typewriter
¯2⌽⍵
\family default
 rotates (with wrapping) 
\family typewriter
⍵
\family default
 two positions to the right along the last axis.
 Writing 
\family typewriter
⌽[x]
\family default
 or 
\family typewriter
⊖[x]
\family default
specifies rotation along axis 
\family typewriter
x
\family default
.
 
\end_layout

\begin_layout Verbatim

      ¯1⊖3 5⍴1 2 3 4 ⍝ Shift down 1 row
\end_layout

\begin_layout Verbatim

3 4 1 2 3
\end_layout

\begin_layout Verbatim

1 2 3 4 1
\end_layout

\begin_layout Verbatim

2 3 4 1 2
\end_layout

\begin_layout Standard
The transpose primitive 
\family typewriter
⍉
\family default
 permutes its argument's axes into different positions.
 Monadic 
\family typewriter
⍉⍵
\family default
 reverses the shape of 
\family typewriter
⍵
\family default
, while giving 
\family typewriter
⍉
\family default
 a left argument indicates how to permute the dimensions.
 Thus, 
\family typewriter
0 1 3 2⍉⍵
\family default
 transposes a hypercube 
\family typewriter
⍵
\family default
 by exchanging the last two axes; likewise, 
\family typewriter
3 0 1 2⍉⍵
\family default
 transposes 
\family typewriter
⍵
\family default
 so that its first axis becomes its last, while all other dimensions retain
 the same relative order.
 The following transposes two matrix slices (sub-arrays) of a cube:
\end_layout

\begin_layout Verbatim

      2 3 3⍴0 1 2 3 4
\end_layout

\begin_layout Verbatim

0 1 2
\end_layout

\begin_layout Verbatim

3 4 0
\end_layout

\begin_layout Verbatim

1 2 3
\end_layout

\begin_layout Verbatim

     
\end_layout

\begin_layout Verbatim

4 0 1
\end_layout

\begin_layout Verbatim

2 3 4
\end_layout

\begin_layout Verbatim

0 1 2
\end_layout

\begin_layout Verbatim

      0 2 1⍉2 3 3⍴0 1 2 3 4
\end_layout

\begin_layout Verbatim

0 3 1
\end_layout

\begin_layout Verbatim

1 4 2
\end_layout

\begin_layout Verbatim

2 0 3
\end_layout

\begin_layout Verbatim

     
\end_layout

\begin_layout Verbatim

4 2 0
\end_layout

\begin_layout Verbatim

0 3 1
\end_layout

\begin_layout Verbatim

1 4 2
\end_layout

\begin_layout Standard
The functions 
\family typewriter
↑
\family default
 and 
\family typewriter
↓
\family default
 resize 
\family typewriter
⍵
\family default
 by taking or dropping elements.
 The expression 
\family typewriter
2 ¯3↑⍵
\family default
 will give a 
\family typewriter
2×3
\family default
 matrix from 
\family typewriter
⍵
\family default
 with rows taken from the top and columns taken from the right, since a
 negative size takes from the tail instead of the head.
 Drop (
\family typewriter
↓
\family default
) works the same way, but eliminates instead of taking items.
 The following example centers a 
\family typewriter
2×2
\family default
 matrix into a 
\family typewriter
4×4
\family default
 matrix.
 Notice how the matrix is extended using 
\family typewriter
0
\family default
 as the 
\noun on
fill
\noun default
 element.
\end_layout

\begin_layout Verbatim

      2 2⍴1 2 3 4
\end_layout

\begin_layout Verbatim

1 2
\end_layout

\begin_layout Verbatim

3 4
\end_layout

\begin_layout Verbatim

      3 3↑2 2⍴1 2 3 4
\end_layout

\begin_layout Verbatim

1 2 0
\end_layout

\begin_layout Verbatim

3 4 0
\end_layout

\begin_layout Verbatim

0 0 0
\end_layout

\begin_layout Verbatim

      ¯4 ¯4↑3 3↑2 2⍴1 2 3 4
\end_layout

\begin_layout Verbatim

0 0 0 0
\end_layout

\begin_layout Verbatim

0 1 2 0
\end_layout

\begin_layout Verbatim

0 3 4 0
\end_layout

\begin_layout Verbatim

0 0 0 0
\end_layout

\begin_layout Standard
The expression 
\family typewriter
⍺,⍵
\family default
 catenates 
\family typewriter
⍺
\family default
 and 
\family typewriter
⍵
\family default
 together as a single array along the last axis.
 However, in this paper we primarily use 
\family typewriter
,
\family default
 monadically.
 The expression 
\family typewriter
,⍵
\family default
 gives a vector of the elements of 
\family typewriter
⍵
\family default
, collapsing the axes of 
\family typewriter
⍵
\family default
 into a single axis whose size is the product of the axes of 
\family typewriter
⍵
\family default
.
 We write 
\family typewriter
,[d]⍵
\family default
 to collapse the specified axes 
\family typewriter
d
\family default
 to a single axis.
 The following example collapses the trailing two axes of a cube, creating
 a matrix:
\end_layout

\begin_layout Verbatim

      2 3 3⍴0 1 2 3 4
\end_layout

\begin_layout Verbatim

0 1 2
\end_layout

\begin_layout Verbatim

3 4 0
\end_layout

\begin_layout Verbatim

1 2 3
\end_layout

\begin_layout Verbatim

     
\end_layout

\begin_layout Verbatim

4 0 1
\end_layout

\begin_layout Verbatim

2 3 4
\end_layout

\begin_layout Verbatim

0 1 2
\end_layout

\begin_layout Verbatim

      ,[1 2]2 3 3⍴0 1 2 3 4
\end_layout

\begin_layout Verbatim

0 1 2 3 4 0 1 2 3
\end_layout

\begin_layout Verbatim

4 0 1 2 3 4 0 1 2
\end_layout

\begin_layout Standard
We write 
\family typewriter
N⌿⍵
\family default
 or 
\family typewriter
N/⍵
\family default
 to mean the array 
\family typewriter
⍵
\family default
 with each element duplicated 
\family typewriter
N
\family default
 times along the first or last axis, respectively:
\end_layout

\begin_layout Verbatim

      2 2⍴1 2 3 4
\end_layout

\begin_layout Verbatim

1 2
\end_layout

\begin_layout Verbatim

3 4
\end_layout

\begin_layout Verbatim

      2⌿2/2 2⍴1 2 3 4
\end_layout

\begin_layout Verbatim

1 1 2 2
\end_layout

\begin_layout Verbatim

1 1 2 2
\end_layout

\begin_layout Verbatim

3 3 4 4
\end_layout

\begin_layout Verbatim

3 3 4 4
\end_layout

\begin_layout Standard
The expressions 
\family typewriter
f⌿⍵
\family default
 and 
\family typewriter
f/⍵
\family default
 compute the reduction of 
\family typewriter
⍵
\family default
 using function 
\family typewriter
f
\family default
 over the first or last axis, respectively.
 This is often called a right fold in many functional languages.
\end_layout

\begin_layout Verbatim

      +⌿1 2 3 4 5
\end_layout

\begin_layout Verbatim

15
\end_layout

\begin_layout Standard
The dyadic application 
\family typewriter
+.×
\family default
 is the function for matrix multiplication extended to higher dimensions.
 
\end_layout

\begin_layout Standard
We can mutate the elements of an array or bind the result of an expression
 to a name.
 The form 
\family typewriter
V←expr
\family default
 binds 
\family typewriter
V
\family default
 to the result of 
\family typewriter
expr
\family default
.
 The expression 
\family typewriter
A[i]
\family default
←
\family typewriter
expr
\family default
 assigns the elements of 
\family typewriter
expr
\family default
 to the corresponding elements of 
\family typewriter
A
\family default
 according to indices 
\family typewriter
i
\family default
.
 If we have a nested array 
\family typewriter
A
\family default
 in which we want to store a single non-scalar array 
\family typewriter
X
\family default
 at index 
\family typewriter
i
\family default
, we box the value 
\family typewriter
X
\family default
 into a scalar first, using 
\family typewriter
⊂
\family default
, resulting in the expression 
\family typewriter
A[i]←⊂X
\family default
.
 We write 
\family typewriter
i⊃A
\family default
 to extract the same array 
\family typewriter
X
\family default
 from 
\family typewriter
A
\family default
.
\end_layout

\begin_layout Standard
The syntax 
\family typewriter
{expr+ ...}
\family default
 returns a function.
 Within the body of the function, consisting of a set of expressions, 
\family typewriter
⍺
\family default
 is the left argument to the function and 
\family typewriter
⍵
\family default
 is the right, while 
\family typewriter
∇
\family default
 refers to the function itself, permitting anonymous recursion.
 Functions execute expressions in order and return the first unbound expression
 or the last bound expression.
\end_layout

\begin_layout Verbatim

      add1←{1+⍵}
\end_layout

\begin_layout Verbatim

      add1 3 4 5
\end_layout

\begin_layout Verbatim

4 5 6
\end_layout

\begin_layout Section
Implementation
\end_layout

\begin_layout Subsection
Overview
\end_layout

\begin_layout Standard
Our implementation of U-net divides into two significant considerations:
 the implementation of the fundamental vocabulary of neural networks and
 the wiring of those operations into the actual U-net architecture.
 We leverage features of APL to implement both aspects of the system, and
 so we treat each in its own sub-section.
 
\end_layout

\begin_layout Standard
Because Co-dfns does not yet support the complete array of Dyalog primitives
 and their semantics, we could enhance some implementation techniques through
 the use of the richer feature-set.
 The effect of these features would be increased concision and clarity,
 but such improvements would not significantly affect the overall performance
 of the code, either positively or negatively.
 The overall structure of the code is clear and simple enough in its current
 state to warrant inclusion almost verbatim, but some adjustments were made
 to reduce the total number of primitives used, which makes the code slightly
 less elegant while reducing the burden to the reader to learn more APL
 primitives.
\end_layout

\begin_layout Standard
One area deserving particular attention is the design of APL as a language
 itself and the features that present themselves as well-suited to expressing
 neural network computations.
 Our exploration of these features uncovered design tensions worth discussing
 in detail.
 A complete copy of the code discussed in this paper is included in the
 appendices.
\end_layout

\begin_layout Subsection
Design of APL Primitives for Neural Networks
\end_layout

\begin_layout Standard
The majority of APL primitives find fundamental use in computing neural
 networks, which isn't surprising given the array-oriented and numerical
 nature of the domain.
 However, the stencil operator, introduced in Dyalog APL 
\begin_inset CommandInset citation
LatexCommand citep
key "stencil-lives"
literal "false"

\end_inset

, stands out as the most obviously aligned with convolutional neural networks.
 The J programming language introduced an alternative implementation of
 the stencil operator earlier 
\begin_inset CommandInset citation
LatexCommand citep
key "stencil-in-J"
literal "false"

\end_inset

, from which Dyalog derived inspiration for the implementation of their
 own stencil operator.
 We propose an alternative that was first suggested to us by the late Roger
 Hui, the stencil 
\noun on
function
\noun default
 
\begin_inset CommandInset citation
LatexCommand citep
key "SF-hui-blog"
literal "false"

\end_inset

.
 The stencil function is a function whose left argument is the same as the
 right operand of the stencil operator, and which receives the same right
 argument as the right argument to the function returned by the stencil
 operator.
 A reasonable definition (padded) of the stencil function using the Dyalog
 stencil operator might be:
\end_layout

\begin_layout Verbatim

SF←{({⍵}⌺⍺)⍵}
\end_layout

\begin_layout Standard
A naïve implementation of the stencil function that did not pad its results
 was implemented in Co-dfns and used in U-net implementation.
 We subsequently use 
\family typewriter
⌺
\family default
 to mean the stencil 
\noun on
function
\noun default
 without padding and not the stencil 
\noun on
operator
\noun default
 as it appears in Dyalog APL.
 Given a specification 
\family typewriter
s
\family default
 as the left argument, the stencil function, written 
\family typewriter
s⌺a
\family default
, returns an array of each sliding window slice of 
\family typewriter
a
\family default
 specified by 
\family typewriter
s
\family default
.
 The first row of the specification indicates the window sizes while the
 second row indicates the step size, or 1 if omitted.
 The window is conceptually 
\begin_inset Quotes eld
\end_inset

slid
\begin_inset Quotes erd
\end_inset

 along the leading axes of the input array.
 The two most common sliding window sizes for 
\family typewriter
⌺
\family default
 in U-net are 
\family typewriter
3 3
\family default
 for convolutions, corresponding to a window size of 
\family typewriter
3×3
\family default
 and a step of 
\family typewriter
1
\family default
 for each axis, and 
\family typewriter
2 2⍴2
\family default
 (a 2 by 2 matrix of 2's) for the max pooling layers and up convolutions,
 corresponding to a 
\family typewriter
2×2
\family default
 window size and a step of 
\family typewriter
2
\family default
 for each axis.
\end_layout

\begin_layout Standard
For example, a 
\family typewriter
3 3
\family default
 sliding window of step 1 on a 
\family typewriter
6 6
\family default
 matrix returns an array of shape 
\family typewriter
4 4 3 3
\family default
 consisting of 16 
\family typewriter
3 3
\family default
 matrix slices arranged in a 
\family typewriter
4 4
\family default
 grid.
 The dimensions of the two leading axes will shrink by 2 each time because
 we implemented stencil without padding.
\end_layout

\begin_layout Verbatim

      6 6⍴⍳36
\end_layout

\begin_layout Verbatim

 0  1  2  3  4  5
\end_layout

\begin_layout Verbatim

 6  7  8  9 10 11
\end_layout

\begin_layout Verbatim

12 13 14 15 16 17
\end_layout

\begin_layout Verbatim

18 19 20 21 22 23
\end_layout

\begin_layout Verbatim

24 25 26 27 28 29
\end_layout

\begin_layout Verbatim

30 31 32 33 34 35
\end_layout

\begin_layout Verbatim

      ⍴3 3⌺6 6⍴⍳36
\end_layout

\begin_layout Verbatim

4 4 3 3
\end_layout

\begin_layout Standard
In the following, we box each 
\family typewriter
3 3
\family default
 matrix slice using 
\family typewriter
⊂[2 3]
\family default
 to show the slices in a more compact form as a nested matrix of matrices,
 but the result of 
\family typewriter
⌺
\family default
 is actually a rank 4 hypercube in this case.
\end_layout

\begin_layout Verbatim

      ⊂[2 3]3 3⌺6 6⍴⍳36
\end_layout

\begin_layout Verbatim

┌────────┬────────┬────────┬────────┐
\end_layout

\begin_layout Verbatim

│ 0  1  2│ 1  2  3│ 2  3  4│ 3  4  5│
\end_layout

\begin_layout Verbatim

│ 6  7  8│ 7  8  9│ 8  9 10│ 9 10 11│
\end_layout

\begin_layout Verbatim

│12 13 14│13 14 15│14 15 16│15 16 17│
\end_layout

\begin_layout Verbatim

├────────┼────────┼────────┼────────┤
\end_layout

\begin_layout Verbatim

│ 6  7  8│ 7  8  9│ 8  9 10│ 9 10 11│
\end_layout

\begin_layout Verbatim

│12 13 14│13 14 15│14 15 16│15 16 17│
\end_layout

\begin_layout Verbatim

│18 19 20│19 20 21│20 21 22│21 22 23│
\end_layout

\begin_layout Verbatim

├────────┼────────┼────────┼────────┤
\end_layout

\begin_layout Verbatim

│12 13 14│13 14 15│14 15 16│15 16 17│
\end_layout

\begin_layout Verbatim

│18 19 20│19 20 21│20 21 22│21 22 23│
\end_layout

\begin_layout Verbatim

│24 25 26│25 26 27│26 27 28│27 28 29│
\end_layout

\begin_layout Verbatim

├────────┼────────┼────────┼────────┤
\end_layout

\begin_layout Verbatim

│18 19 20│19 20 21│20 21 22│21 22 23│
\end_layout

\begin_layout Verbatim

│24 25 26│25 26 27│26 27 28│27 28 29│
\end_layout

\begin_layout Verbatim

│30 31 32│31 32 33│32 33 34│33 34 35│
\end_layout

\begin_layout Verbatim

└────────┴────────┴────────┴────────┘
\end_layout

\begin_layout Standard
Notice that the window slides along the leading axes, so each slice captures
 all trailing axes for each slice.
\end_layout

\begin_layout Subsection
Neural Network Vocabulary
\begin_inset CommandInset label
LatexCommand label
name "subsec:Neural-Network-Vocabulary"

\end_inset


\end_layout

\begin_layout Standard
The original U-net paper uses five distinct operations to describe the network
 (see 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:unet-architecture"
plural "false"
caps "false"
noprefix "false"

\end_inset

):
\end_layout

\begin_layout Enumerate
A 
\family typewriter
3×3
\family default
 convolution with a ReLU activation function is used as the primary operation
\end_layout

\begin_layout Enumerate
A copy and crop operation is used to transfer data across one row of the
 network
\end_layout

\begin_layout Enumerate
Max pooling layers on a 
\family typewriter
2×2
\family default
 window are used to compute 
\begin_inset Quotes eld
\end_inset

down
\begin_inset Quotes erd
\end_inset

 the network
\end_layout

\begin_layout Enumerate
A 
\family typewriter
2×2
\family default
 transposed convolution goes back 
\begin_inset Quotes eld
\end_inset

up
\begin_inset Quotes erd
\end_inset

 the network
\end_layout

\begin_layout Enumerate
The final output has a single 
\family typewriter
1×1
\family default
 convolution with a soft-max layer
\end_layout

\begin_layout Standard
In our implementation, we mirror this vocabulary by implementing the forward
 and back functions for each of these layers, one for each of the above
 operations.
 This results in a total of 10 functions grouped into 5 pairs, which we
 will take in turn.
\end_layout

\begin_layout Standard
Each of our operations works over a given network 
\begin_inset Quotes eld
\end_inset

layer,
\begin_inset Quotes erd
\end_inset

 which is a cube of shape 
\family typewriter
N M C
\family default
 where 
\family typewriter
N M
\family default
 are the layer dimensions and 
\family typewriter
C
\family default
 is the number of layer channels.
 
\end_layout

\begin_layout Subsubsection
Convolution (3×3) with ReLU
\end_layout

\begin_layout Standard
The primary U-net convolutional kernel is a 3×3 convolution with a ReLU
 activation function.
 The convolution in the paper uses 
\begin_inset Quotes eld
\end_inset

valid
\begin_inset Quotes erd
\end_inset

 convolutions, meaning that no padding is used.
 This implies that the convolution dimensions of the output array shrink
 by 2 for each dimension compared to the input.
 We define the forward propagation function 
\family typewriter
CV
\family default
 as a function over a kernel 
\family typewriter
⍺
\family default
 of shape 
\family typewriter
3 3 I O
\family default
 of 
\family typewriter
I
\family default
 input channels and 
\family typewriter
O
\family default
 output channels with a layer 
\family typewriter
⍵
\family default
 of shape 
\family typewriter
N M I
\family default
 that obeys the following shape invariant:
\end_layout

\begin_layout Verbatim

⍴⍺ CV ⍵ ←→ (¯2+2↑⍴⍵),¯1↑⍴⍺
\end_layout

\begin_layout Standard
This says that the size of the first two axes of 
\family typewriter
⍺ CV ⍵
\family default
 will be two less than the first two axes of 
\family typewriter
⍵
\family default
, while the remaining axis, corresponding to the output channels, will match
 the last axis of 
\family typewriter
⍺
\family default
.
 In other words, given the kernel of shape 
\family typewriter
3 3 I O
\family default
 and layer of shape 
\family typewriter
N M I
\family default
, the result of 
\family typewriter
⍺ CV ⍵
\family default
 will have shape 
\family typewriter
(N-2) (M-2) O
\family default
.
 Using the stencil function, we define 
\family typewriter
CV
\family default
 as follows for rank 4 kernel inputs and rank 3 layer inputs:
\end_layout

\begin_layout Verbatim

CV←{0⌈(,[2 3 4]3 3⌺⍵)+.×,[0 1 2]⍺}
\end_layout

\begin_layout Standard
The result of the expression 
\family typewriter
3 3⌺⍵
\family default
 will have a rank of 5 and shape 
\family typewriter
(N-2) (M-2) 3 3 I
\family default
, so raveling the trailing dimensions with the expression 
\family typewriter
,[2 3 4]3 3⌺⍵
\family default
 gives us a cube of shape 
\family typewriter
(N-2) (M-2) (3×3×I)
\family default
 while the expression 
\family typewriter
,[0 1 2]⍺
\family default
 gives us a matrix of shape 
\family typewriter
(3×3×I) O
\family default
.
 We use the extended matrix multiplication 
\family typewriter
+.×
\family default
 to compute the convolution, resulting in a cube of shape 
\family typewriter
N M O
\family default
.
 The ReLU function 
\family typewriter
0⌈⍵
\family default
 follows as the final operation.
 
\end_layout

\begin_layout Standard
Computing backpropagation uses very similar approaches.
 Given the output layer 
\family typewriter
z
\family default
, input layer 
\family typewriter
x
\family default
, activation layer 
\family typewriter
a
\family default
, weights 
\family typewriter
⍺
\family default
, and the gradient backpropagated so far 
\family typewriter
⍵
\family default
, we compute the transposed weights 
\family typewriter
w
\family default
, the derivative output layer 
\family typewriter
∆z
\family default
, the weight gradient 
\family typewriter
∆w
\family default
, padded output layer 
\family typewriter
∆Z
\family default
, and the resulting back gradient 
\family typewriter
∆x
\family default
 as follows:
\end_layout

\begin_layout Verbatim

∆CV←{
\end_layout

\begin_layout Verbatim

     w←⊖⌽[1]0 1 3 2⍉⍺
\end_layout

\begin_layout Verbatim

    ∆z←⍵×0<a
\end_layout

\begin_layout Verbatim

    ∆w←3 0 1 2⍉(⍉,[0 1]∆z)+.×,[0 1]3 3⌺x
\end_layout

\begin_layout Verbatim

    ∆Z←¯2⊖¯2⌽[1](4+2↑⍴∆z)↑∆z
\end_layout

\begin_layout Verbatim

    ∆x←(,[2 3 4]3 3⌺∆Z)+.×,[0 1 2]w
\end_layout

\begin_layout Verbatim

}
\end_layout

\begin_layout Standard
Since our stencil function does not pad its results, the expression 
\family typewriter
¯2⊖¯2⌽[1](4+2↑⍴∆z)↑∆z
\family default
 expands the shape of 
\family typewriter
∆z
\family default
 to ensure that the output convolution dimensions are 2 greater than those
 of 
\family typewriter
∆z
\family default
.
\end_layout

\begin_layout Subsubsection
Copy and Crop
\end_layout

\begin_layout Standard
Conceptually, the copy and crop operation is the simplest of the functions
 in U-net.
 Its sole job is to take the output from one side of the U-shaped net and
 move it over to the other side, adjusting the dimensions to ensure that
 it fits.
 In the forward direction, the input layer will have a greater dimension
 than the output layer, so we crop as evenly as possible around the edges
 and then catenate the result at the head of the layer coming 
\begin_inset Quotes eld
\end_inset

up
\begin_inset Quotes erd
\end_inset

 from the network to form the output layer with twice the channels of the
 
\begin_inset Quotes eld
\end_inset

up
\begin_inset Quotes erd
\end_inset

 layer.
 The following function 
\family typewriter
CC
\family default
 computes the crop of 
\family typewriter
⍺
\family default
 catenated with 
\family typewriter
⍵
\family default
 using 
\family typewriter
↓
\family default
:
\end_layout

\begin_layout Verbatim

CC←{
\end_layout

\begin_layout Verbatim

    p←((⍴⍺)-⍴⍵)÷2),⍵
\end_layout

\begin_layout Verbatim

    ((⌊p)↓(-⌈p)↓⍺
\end_layout

\begin_layout Verbatim

}
\end_layout

\begin_layout Standard
For dimensions not evenly divisible by two, we choose to round up on the
 right and bottom sides and round down on the left and upper sides of the
 layer.
 Computing the backpropagation of 
\family typewriter
CC
\family default
 given the input 
\family typewriter
⍺
\family default
 and output gradient 
\family typewriter
⍵
\family default
 simply reverses this operation and expands the shape back to the original
 input size.
 This result is then added to the appropriate layer in the U-net architecture
 described in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "subsec:U-net-Architecture"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 
\end_layout

\begin_layout Verbatim

∆CC←{
\end_layout

\begin_layout Verbatim

    n m←-⌊(2↑(⍴⍺)-⍴⍵)÷2
\end_layout

\begin_layout Verbatim

    ∆x←n⊖m⌽[1](⍴⍺)↑⍵
\end_layout

\begin_layout Verbatim

}
\end_layout

\begin_layout Subsubsection
Max Pooling
\end_layout

\begin_layout Standard
Max pooling is a shrinking convolution that computes the maximum value in
 a non-overlapping sliding window.
 Given the stencil function, the max pool over a layer is given by the following
 definition for 
\family typewriter
MX
\family default
:
\end_layout

\begin_layout Verbatim

MX←{⌈⌿[2],[2 3](2 2⍴2)⌺⍵}
\end_layout

\begin_layout Standard
Here we write 
\family typewriter
⌈⌿[2],[2 3]⍵
\family default
 to describe an array where we have collapsed dimensions 2 and 3 and computed
 the maximum value reduction over the resulting dimension.
 For example, given an input layer 
\family typewriter
⍵
\family default
 of shape 
\family typewriter
N M C
\family default
, the result of 
\family typewriter
(2 2⍴2)⌺⍵
\family default
 is a rank 5 array of shape 
\family typewriter
(N÷2) (M÷2) 2 2 C
\family default
.
 We then collapse axes 2 and 3 to form an array of shape 
\family typewriter
(N÷2) (M÷2) 4 C
\family default
 and subsequently find the maximum value for each vector along axis 2, resulting
 in an array of shape 
\family typewriter
(N÷2) (M÷2) C
\family default
.
\end_layout

\begin_layout Standard
Computing the backpropagation of this involves replicating each of the stencil
 dimensions, which are the two leading axes in our implementation.
 Given an input 
\family typewriter
⍺
\family default
 and output layer 
\family typewriter
⍵
\family default
 the following function 
\family typewriter
∆MX
\family default
 computes the backpropagation:
\end_layout

\begin_layout Verbatim

∆MX←{
\end_layout

\begin_layout Verbatim

    y←(⍴⍺)↑2⌿2/[1]⍵
\end_layout

\begin_layout Verbatim

    y×⍺=y
\end_layout

\begin_layout Verbatim

}
\end_layout

\begin_layout Subsubsection
Transposed Convolution (2×2)
\end_layout

\begin_layout Standard
The upsampling computation with convolution proved to be the most subtle
 and challenging, mostly due to the opaqueness of implementations.
 The U-net paper was not immediately transparent regarding the exact operations
 used for this layer and there were a number of potential design decisions
 that could have been made.
 Moreover, for users reading about upsampling through convolutions, the
 descriptions are also the furthest removed from a reasonable implementation
 of the same.
 However, once the intuition hits that an upsampling convolution matches
 the shape and form of a non-overlapping sliding window in the output layer,
 the computation becomes much clearer.
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
name "https://mathspp.com/blog/til/033"
target "https://mathspp.com/blog/til/033"
literal "false"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
For this convolution, we change the anticipated kernel shape from that used
 for 
\family typewriter
CV
\family default
 above.
 Whereas 
\family typewriter
CV
\family default
 expects kernels of shape 
\family typewriter
3 3 I O
\family default
, our transposed convolutions expect kernels of shape 
\family typewriter
I 2 2 O
\family default
 for input channels 
\family typewriter
I
\family default
 and output channels 
\family typewriter
O
\family default
.
 With a layer of standard shape 
\family typewriter
N M I
\family default
, this gives the following definition for the upsampling pass:
\end_layout

\begin_layout Verbatim

UP←{,[0 1],[2 3]0 2 1 3 4⍉⍵+.×⍺}
\end_layout

\begin_layout Standard
The key change here from the reliance on 
\family typewriter
+.×
\family default
 with 
\family typewriter
CV
\family default
 is the use of a dyadic transpose.
 The input into the 
\family typewriter
⍉
\family default
 transpose is the result of 
\family typewriter
⍵+.×⍺
\family default
 which has shape 
\family typewriter
N M 2 2 O
\family default
.
 Thus, the expression 
\family typewriter
0 2 1 3 4⍉⍵+.×⍺
\family default
 returns an array of shape 
\family typewriter
N 2 M 2 O
\family default
.
 As the final operation, we collapse the first two pairs of leading dimensions,
 giving a final output array of shape 
\family typewriter
(N×2) (M×2) O
\family default
.
 
\end_layout

\begin_layout Standard
To compute the backpropagation pass, we compute the convolutions on a 
\family typewriter
2×2
\family default
 sliding window with stride 2.
\end_layout

\begin_layout Verbatim

∆UP←{
\end_layout

\begin_layout Verbatim

    ∆w←(⍉,[0 1]x)+.×,[0 1](2 2⍴2)⌺∆z
\end_layout

\begin_layout Verbatim

    ∆x←(,[2 3 4](2 2⍴2)⌺∆z)+.×⍉,[1 2 3]⍺
\end_layout

\begin_layout Verbatim

}
\end_layout

\begin_layout Subsubsection
Final 1×1 Convolution
\end_layout

\begin_layout Standard
The final convolution is a 
\family typewriter
1×1
\family default
 convolution with 2 output channels, which means that it collapses the final
 incoming channels into an output layer with only two channels.
 This gives the trivial simplification of our convolution code over layer
 
\family typewriter
⍵
\family default
 and kernel 
\family typewriter
⍺
\family default
 of 
\family typewriter
⍵+.×⍺
\family default
, which we combine with the soft-max layer described in the paper:
\end_layout

\begin_layout Verbatim

C1←{
\end_layout

\begin_layout Verbatim

    z←⍵+.×⍺
\end_layout

\begin_layout Verbatim

    z←*z-[0 1]⌈/z
\end_layout

\begin_layout Verbatim

    1E¯8+z÷[0 1] +/z
\end_layout

\begin_layout Verbatim

}
\end_layout

\begin_layout Standard
Computing the backpropagation is likewise a simplification of the more complex
 
\family typewriter
CV
\family default
 code:
\end_layout

\begin_layout Verbatim

∆C1←{
\end_layout

\begin_layout Verbatim

    ∆w←(⍉,[0 1]x)+.×,[0 1]∆z
\end_layout

\begin_layout Verbatim

    ∆x←∆z+.×⍉w
\end_layout

\begin_layout Verbatim

}
\end_layout

\begin_layout Standard
\begin_inset Float table
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
A rectangular arrangement of the U-net network
\begin_inset CommandInset label
LatexCommand label
name "tab:A-rectangular-arrangement"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="7" columns="11">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top" width="0pt">
<column alignment="right" valignment="top">
<column alignment="right" valignment="top">
<column alignment="right" valignment="top">
<column alignment="left" valignment="top">
<column alignment="right" valignment="top">
<column alignment="right" valignment="top" width="0pt">
<column alignment="right" valignment="top">
<column alignment="left" valignment="top">
<column alignment="right" valignment="top">
<column alignment="right" valignment="top">
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\noun on
Operation
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="left" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $CV$
\end_inset


\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="left" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $CV$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $MX$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $CV$
\end_inset


\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $CV$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $UP$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="center" valignment="top" rotate="90" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\noun on
Depth
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
0
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\family typewriter
\size tiny
\begin_inset Formula $\texttt{3\ 3\ \ \ 1\ \ 64}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
\begin_inset Formula $\texttt{3 3 \ 64 \ 64}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
\begin_inset Formula $\texttt{0 0 \ 64 \ 64}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
\begin_inset Formula $\texttt{3 3 \ 256 \ 128}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
\begin_inset Formula $\texttt{3 3 \ 128 \ 128}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
\begin_inset Formula $\texttt{\ 128 2 2 \ 64}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
1
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="right" valignment="middle" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
\begin_inset Formula $\texttt{3\ 3\ \ 64\ 128}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
\begin_inset Formula $\texttt{3 3 128 128}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
\begin_inset Formula $\texttt{0 0 128 128}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
\begin_inset Formula $\texttt{3 3 \ 512 \ 256}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
\begin_inset Formula $\texttt{3 3 \ 256 \ 256}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
\begin_inset Formula $\texttt{\ 256 2 2 128}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
2
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
\begin_inset Formula $\texttt{3 3 128 256}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
\begin_inset Formula $\texttt{3 3 256 256}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
\begin_inset Formula $\texttt{0 0 256 256}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
\begin_inset Formula $\texttt{3 3 1024 \ 512}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
\begin_inset Formula $\texttt{3 3 \ 512 \ 512}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
\begin_inset Formula $\texttt{\ 512 2 2 256}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
3
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
\begin_inset Formula $\texttt{3 3 256 512}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
\begin_inset Formula $\texttt{3 3 512 512}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
\begin_inset Formula $\texttt{0 0 512 512}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
\begin_inset Formula $\texttt{3 3 \ 512 1024}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
\begin_inset Formula $\texttt{3 3 1024 1024}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size tiny
\begin_inset Formula $\texttt{1024 2 2 512}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\emph on
Downward Pass
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\emph on
Upward Pass
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
U-Net Architecture
\begin_inset CommandInset label
LatexCommand label
name "subsec:U-net-Architecture"

\end_inset


\end_layout

\begin_layout Standard
Given the core vocabularies defined in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "subsec:Neural-Network-Vocabulary"
plural "false"
caps "false"
noprefix "false"

\end_inset

, the remaining challenge with implementing U-net is to link together the
 appropriate layers and compositions to form the complete network as described
 by 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:unet-architecture"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 To do this, we observe that the structure of the U-net diagram is an almost
 symmetric pattern.
 The output layer computations form three operations which are not part
 of the pattern, but the rest of the pattern decomposes into 4 depths, each
 with 6 operations each.
 
\begin_inset CommandInset ref
LatexCommand formatted
reference "tab:A-rectangular-arrangement"
plural "false"
caps "false"
noprefix "false"

\end_inset

 contains a visual arrangement of the kernel shapes used in our architecture
 mirroring the overall structure of 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:unet-architecture"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 
\end_layout

\begin_layout Standard
Additionally, we note that the U-shaped structure also mimics the down and
 up nature of a recursive program call-tree.
 Thus, our overall strategy is to implement a recursive function 
\family typewriter
LA
\family default
 that receives an index identifying a particular depth of the network, computes
 the appropriate 
\begin_inset Quotes eld
\end_inset

downward pass
\begin_inset Quotes erd
\end_inset

 operations before recurring deeper into the network and finally computing
 the upwards passes on the return of its recursive call.
 We likewise implement backpropagation in same way, but in the opposite
 direction.
 Assuming that 
\family typewriter
⍺
\family default
 contains the computed depth offset for the network layer, we write 
\family typewriter
⍺+i
\family default
 to access the 
\begin_inset Formula $i$
\end_inset

th column of the network described in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "tab:A-rectangular-arrangement"
plural "false"
caps "false"
noprefix "false"

\end_inset

 at the depth 
\family typewriter
⍺÷6
\family default
.
 
\end_layout

\begin_layout Standard
Our architecture is agnostic to any specific size of kernels or depth of
 the 
\begin_inset Quotes eld
\end_inset

U
\begin_inset Quotes erd
\end_inset

; using greater depth with larger resolutions is possible simply by providing
 a different network of kernels as input.
 Many systems typically allocate networks statically, including our own
 PyTorch implementation.
 Our implementation instead assumes a network defined by a set of kernels
 
\family typewriter
W
\family default
 that match the expected shape.
 We mirror the 
\family typewriter
W
\family default
 network with our intermediate results in 
\family typewriter
Z
\family default
 so that we can do backpropagation.
 The full code for our layers extract their values from these 
\family typewriter
Z
\family default
 and 
\family typewriter
W
\family default
 vectors directly using expressions like 
\family typewriter
⍺⊃W
\family default
 to extract the weights for the layer at index 
\family typewriter
⍺
\family default
.
 We likewise store intermediate results with expressions like 
\family typewriter
Z[⍺]←⊂⍵
\family default
.
\end_layout

\begin_layout Standard
Our forward pass function is responsible for initializing 
\family typewriter
Z
\family default
 to hold the intermediate results produced by forward propagation for use
 by the backpropagation function.
 After the recursive computation, there are the final three operations,
 
\family typewriter
C1
\family default
 and two 
\family typewriter
CV
\family default
 operations, that must be called before returning.
 We assume that we may receive a rank 2 matrix instead of a rank 3 layer
 as input, and so we reshape the input to ensure that we always have a rank
 3 input to 
\family typewriter
LA
\family default
.
 This gives us the following function definition:
\end_layout

\begin_layout Verbatim

FWD←{
\end_layout

\begin_layout Verbatim

  Z⊢←(≢W)⍴⊂⍬
\end_layout

\begin_layout Verbatim

  ⍝ Forward propagation layers ...
\end_layout

\begin_layout Verbatim

  LA←{
\end_layout

\begin_layout Verbatim

    ⍺≥≢Z:⍵
\end_layout

\begin_layout Verbatim

    down←(⍺+6)∇(⍺+2)MX(⍺+1)CV(⍺+0)CV ⍵
\end_layout

\begin_layout Verbatim

    (⍺+2)CC(⍺+5)UP(⍺+4)CV(⍺+3)CV down
\end_layout

\begin_layout Verbatim

  }
\end_layout

\begin_layout Verbatim

  2 C1 1 CV 0 CV 3 LA (3↑(⍴⍵),1)⍴⍵
\end_layout

\begin_layout Verbatim

}
\end_layout

\begin_layout Standard
The backwards computation mirrors this pattern, except that it proceeds
 in the opposite direction and also defines an updater function 
\family typewriter
∆
\family default
 that will update the network weights in 
\family typewriter
W
\family default
 and the velocities in 
\family typewriter
V
\family default
 based on a given gradient 
\family typewriter
⍵
\family default
 and index 
\family typewriter
⍺
\family default
 pointing to a specific location in the network.
 
\end_layout

\begin_layout Verbatim

BCK←{
\end_layout

\begin_layout Verbatim

  Y←⍺ ⋄ Y∆←⍵
\end_layout

\begin_layout Verbatim

  ∆←{
\end_layout

\begin_layout Verbatim

    V[⍺]←⊂⍵+MO×(⍴⍵)⍴⍺⊃V
\end_layout

\begin_layout Verbatim

    W[⍺]←⊂(⍺⊃W)-LR×⍺⊃V
\end_layout

\begin_layout Verbatim

  }
\end_layout

\begin_layout Verbatim

  ⍝ Back propagation layers ...
\end_layout

\begin_layout Verbatim

  ∆LA←{
\end_layout

\begin_layout Verbatim

    ⍺≥≢Z:⍵
\end_layout

\begin_layout Verbatim

    up←(⍺+5)∆UP(-(≢⍉⍵)÷2)↑[2]⍵
\end_layout

\begin_layout Verbatim

    down←(⍺+6)∇(⍺+3)∆CV(⍺+4)∆CV up
\end_layout

\begin_layout Verbatim

    mx←(⍺+2)∆MX down
\end_layout

\begin_layout Verbatim

    (⍺+0)∆CV(⍺+1)∆CV mx+(⍺+2)∆CC ⍵
\end_layout

\begin_layout Verbatim

  }
\end_layout

\begin_layout Verbatim

  diff←Y∆-(~Y),[1.5]Y
\end_layout

\begin_layout Verbatim

  3 ∆LA 0 ∆CV 1 ∆CV 2 ∆C1 diff
\end_layout

\begin_layout Verbatim

}
\end_layout

\begin_layout Section
Performance
\end_layout

\begin_layout Standard
We primarily focused on comparing our U-net implementation against a reference
 implemented in PyTorch 
\begin_inset CommandInset citation
LatexCommand citep
key "pytorch"
literal "false"

\end_inset

, which is an easy to use Python framework with good performance.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename benchmark-comp.eps
	width 100text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Performance results for U-net across a range of platforms
\begin_inset CommandInset label
LatexCommand label
name "fig:Performance-results-for"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

We were primarily interested in the costs of executing a single run of the
 U-net over a single image source in both the forwards and backwards directions.
 We compared performance over the following platforms:
\end_layout

\begin_layout Itemize
Dyalog APL 18.0 64-bit Windows interpreter
\end_layout

\begin_layout Itemize
Co-dfns (v4.1.0 master branch) using the CUDA backend (AF v3.8.1)
\end_layout

\begin_layout Itemize
Co-dfns (v4.1.0 master branch) using the CPU backend (AF v3.8.1)
\end_layout

\begin_layout Itemize
PyTorch v1.10.2 with the CUDA GPU backend
\end_layout

\begin_layout Itemize
PyTorch v1.10.2 with the multi-threaded CPU backend
\end_layout

\begin_layout Itemize
PyTorch v1.10.2 with the single-threaded CPU backend
\end_layout

\begin_layout Standard
The results of the execution can be seen in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:Performance-results-for"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 The timings do not include the cost of reading the image data from disk,
 but they do include the costs of transferring the image input data and
 the resulting error and forward propagation results back to the CPU main
 memory.
 In our testing, data transfer costs in Co-dfns accounted for significantly
 less than 5% of the total runtime.
 
\end_layout

\begin_layout Standard
The hardware used was an NVIDIA GeForce RTX 3070 Laptop GPU with 8GB of
 dedicated graphics memory.
 We used NVIDIA driver version 511.65.
 The CPU was an Intel Core i7-10870H with 16 logical cores @ 2.2GHz.
 Main system memory was 32GB of DDR4 RAM.
 The system was running an up to date release of Microsoft Windows 11.
 
\end_layout

\begin_layout Standard
As input we used the original image data from the ISBI benchmark referenced
 in the U-net paper 
\begin_inset CommandInset citation
LatexCommand citep
key "unet,isbi-data"
literal "false"

\end_inset

.
 These images are 
\begin_inset Formula $512\times512$
\end_inset

 images in grayscale with a binary mask for training.
 Each run took one of these images and associated training mask and computed
 the result of forward and backwards propagation and the error as well as
 updating the weights for the network.
 
\end_layout

\begin_layout Standard
When working on the network, APL implementations generally do not have a
 concept of small floating point values.
 Rather, their default is to always use 64-bit floating point values when
 floats are called for.
 In order to try to mimic this behavior as closely as possible, we attempted
 to feed 64-bit data into the PyTorch models.
 However, because of the opaqueness of the PyTorch implementation, we were
 not able to fully verify that 64-bit values are used throughout the PyTorch
 computational network.
 On the other hand, the reliance on 64-bit only floating points, while a
 boon to convenience and user-friendliness for non-computer science programmers,
 creates well-defined performance issues for an application like this.
\end_layout

\begin_layout Standard
When running the benchmark, we computed the average of 10 runs, ensuring
 that we discarded the first run each time, since these runs often contained
 significant setup and bootstrapping code (PyTorch's optimizer, the JIT
 optimization in Co-dfns, and so forth).
 The figure includes information about the variance of the individual runs
 as well as the average run time in seconds.
 
\end_layout

\begin_layout Standard
Examining the data, it is clear why traditional APL implementations were
 relatively unsuited to extensive use within the machine learning space.
 Dyalog's interpreter preformed the slowest by a very large magnitude.
 After this, the single-threaded CPU implementations in Co-dfns and PyTorch
 are predictably the next slowest, with the Co-dfns implementation running
 about a factor of 2.2 times slower than the equivalent PyTorch implementation.
\end_layout

\begin_layout Standard
When acceleration techniques are employed, the differences in execution
 speed begin to shrink, with PyTorch's multi-threaded and GPU-based implementati
ons coming in fasted, and Co-dfns' GPU backend running at roughly 2.4 times
 slower than the PyTorch GPU execution.
 
\end_layout

\begin_layout Standard
We observed the widest variance in performance results in the Co-dfns CPU
 and Dyalog interpreter-based runs, and very little variance in the GPU-based
 runs or in PyTorch itself.
 
\end_layout

\begin_layout Standard
The stencil function was modeled in APL and used to conduct the above benchmark.
 The model, written in APL, is a naïve implementation of the stencil function
 and contains no special optimizations other than to distinguish between
 sliding windows of step 1 and non-overlapping, adjacent windows (such as
 used for the max pooling layers).
 Additionally, no specialized code was used within Co-dfns that was specific
 or specialized to neural network programming.
 
\end_layout

\begin_layout Standard
The above benchmark therefore represents a comparison of the PyTorch implementat
ion against a naïve and unspecialized implementation in APL executed with
 the general-purpose runtime used in Co-dfns that provides generalized GPU
 computation but does not include domain-specific optimizations such as
 those available in PyTorch.
 
\end_layout

\begin_layout Section
Discussion
\end_layout

\begin_layout Subsection
Performance
\end_layout

\begin_layout Standard
\begin_inset Float table
wide true
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Raw Performance Timings (Secs)
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="7" columns="13">
<features booktabs="true" tabularvalignment="middle">
<column alignment="right" valignment="top" width="0pt">
<column alignment="decimal" decimal_point="." valignment="top" width="0pt">
<column alignment="decimal" decimal_point="." valignment="top" width="0pt">
<column alignment="decimal" decimal_point="." valignment="top" width="0pt">
<column alignment="decimal" decimal_point="." valignment="top" width="0pt">
<column alignment="decimal" decimal_point="." valignment="top" width="0pt">
<column alignment="decimal" decimal_point="." valignment="top" width="0pt">
<column alignment="decimal" decimal_point="." valignment="top" width="0pt">
<column alignment="decimal" decimal_point="." valignment="top" width="0pt">
<column alignment="decimal" decimal_point="." valignment="top" width="0pt">
<column alignment="decimal" decimal_point="." valignment="top" width="0pt">
<column alignment="decimal" decimal_point="." valignment="top" width="0pt">
<column alignment="decimal" decimal_point="." valignment="top" width="0pt">
<row>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
7
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
8
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\emph on
Avg
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
\noun on
Dyalog
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
80.90
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
77.56
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
78.32
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
81.33
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
77.95
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
80.51
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
81.08
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
81.87
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
80.23
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
79.42
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
79.92
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
\noun on
Co-dfns (CPU)
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
34.11
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
33.66
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
35.98
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
37.72
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
38.20
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
38.64
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
38.11
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
38.46
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
38.57
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
38.76
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
37.22
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
\noun on
Co-dfns (GPU)
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
8.39
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
8.20
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
8.62
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
8.63
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
8.49
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
8.39
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
8.19
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
8.63
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
8.51
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
8.59
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
8.46
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
\noun on
PyTorch (CPU)
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
17.27
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
17.34
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
17.21
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
16.60
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
17.46
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
17.01
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
17.33
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
17.04
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
17.36
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
17.33
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
17.22
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
\noun on
PyTorch (SMP)
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
6.31
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
6.42
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
6.45
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
6.19
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
6.67
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
6.49
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
6.43
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
6.38
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
6.36
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
6.55
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
6.42
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="right" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
\noun on
PyTorch (GPU)
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
3.50
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
3.50
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
3.47
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
3.44
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
3.44
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
3.44
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
3.44
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
3.44
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
3.46
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
3.46
\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="decimal" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
3.46
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Clearly, specialized frameworks for deep neural networks are still the best
 way to go in order to achieve the absolute maximum in performance at present.
 However, our results indicate that the gap between reliance on specialized
 frameworks and the freedom to use more general purpose and transferable
 programming languages while still achieving competitive performance is
 not nearly as large as might have been the case even a few years ago.
 
\end_layout

\begin_layout Standard
Given that almost zero special optimization is taking place for the APL
 implementation executed under the Co-dfns runtime, it is impressive that
 we are able to see results that come close to a factor of 2 of the specialized
 frameworks.
 Given some of the obvious design issues that would contribute to slower
 performance, it seems more reasonable to be able to expect more general
 purpose languages like APL to be able to reach performance parity with
 specialized frameworks, without the requirement that the user learn a special
 API, or import specialized dependencies.
 In more complex applications that leverage APL for other domain-intensive
 work, this suggests that APL might facilitate scaling such applications
 to integrate machine learning algorithms more easily and with less programmer
 effort than might be required to integrate a separate framework like PyTorch.
 
\end_layout

\begin_layout Subsection
APL vs.
 Frameworks
\end_layout

\begin_layout Standard
We have demonstrated that APL itself, without libraries or additional dependenci
es, is exceptionally well suited to expressing neural network computations,
 at a level of inherent complexity that is arguably equal or possibly even
 less than that of the reference PyTorch implementation.
 At the very least, it is less code with less underlying background code
 and layers.
 This comes at the admittedly heavy cost of being completely foreign and
 alien to most programmers who are more familiar with languages like Python.
 This certainly creates a fundamental and immediate learning cost to APL
 over other frameworks, since other frameworks can assume a wider range
 of foreknowledge around their chosen language implementation.
 
\end_layout

\begin_layout Standard
It remains unclear, however, whether, if this foreknowledge were taken away,
 APL would represent a compelling value proposition for such programming
 tasks or not.
 Indeed, it is exceptionally challenging to divorce the present reality
 of prior background knowledge from such a question.
 Even fundamental knowledge like what it means to do array programming and
 how to structure problems in an array-style are rarely if ever taught at
 universities, whereas most classes spend significant amounts of time teaching
 students how to utilize the Python-style programming model of PyTorch.
\end_layout

\begin_layout Standard
The argument that APL may be used more widely and broadly than PyTorch on
 a wider range of problems using the same skill-set may not matter to users
 who are only interested in deep learning algorithms.
 
\end_layout

\begin_layout Standard
APL presently has a higher barrier to entry, but rewards the user with full
 and effortless control over what's being done in a way that other systems
 do not.
 This may present itself as a distinct advantage to users who are looking
 to expand 
\begin_inset Quotes eld
\end_inset

off the beaten track
\begin_inset Quotes erd
\end_inset

 and utilize novel approaches that do not easily fit within existing frameworks.
 
\end_layout

\begin_layout Standard
We encountered significant difficulties in identifying exactly what the
 original authors did based on their paper alone because of many implementation
 details that were omitted.
 On the other hand, APL enables us to express our entire implementation
 in a way that makes every implementation detail clear, improving the ability
 of others to reproduce our work.
\end_layout

\begin_layout Standard
Finally, in the implementation of U-net in APL, we gained insights into
 the architecture that had a direct and material influence on the PyTorch
 reference implementation that would not have emerged without first having
 studied the APL implementation.
 Thus, we gained significant insight simply from doing the APL implementation,
 even if we were to re-implement that code in PyTorch.
 
\end_layout

\begin_layout Section
Related Work
\end_layout

\begin_layout Standard
In addition to the Co-dfns compiler, 
\begin_inset CommandInset citation
LatexCommand citet
key "bernecky-cnn"
literal "false"

\end_inset

 have explored alternative implementations to CNNs, though not U-net specificall
y.
 They focused on APL as a productivity enhancement for CNN development,
 and only benchmarked the APL implementation on the CPU using the Dyalog
 APL interpreter.
 They make a case for the usability of APL even with the performance numbers
 they achieved.
 Research in SaC demonstrates implementations competitive with the current
 state of the art 
\begin_inset CommandInset citation
LatexCommand citep
key "sac-cnn"
literal "false"

\end_inset

.
 While their code exhibits some material differences to that given here,
 there are nonetheless some similarities that demonstrate some level of
 convergence around implementing CNNs in APL.
\end_layout

\begin_layout Standard
Another approach to GPU-based array programming with an APL focus is the
 TAIL/Futhark system 
\begin_inset CommandInset citation
LatexCommand citep
key "futhark"
literal "false"

\end_inset

, which is a compiler chain taking APL to the TAIL (Typed Array Intermediate
 Language) and then compiling TAIL code using the Futhark GPU compiler backend.
 Futhark has been used to implement deep learning primitives 
\begin_inset CommandInset citation
LatexCommand citep
key "futhark-deeplearning"
literal "false"

\end_inset

, and it represents an interesting approach to compilation of APL via typed
 intermediate languages, which have the potential to enhance the fusion
 that can be done with an operation like the stencil function.
 
\end_layout

\begin_layout Standard
Other programming environments that are often categorized as array programming
 environments, such as Matlab 
\begin_inset CommandInset citation
LatexCommand citep
key "matlab"
literal "false"

\end_inset

, Julia 
\begin_inset CommandInset citation
LatexCommand citep
key "julia"
literal "false"

\end_inset

, and Python/ Numpy 
\begin_inset CommandInset citation
LatexCommand citep
key "python,numpy"
literal "false"

\end_inset

, are not exceptionally performant on their own for machine learning, but
 often wrap libraries to do so.
 Unfortunately, many of these languages use a syntax that much more closely
 mirrors that of Python than APL.
 In our perspective, this reduces the value proposition of such languages
 over using specialized frameworks, since one does not obtain the particular
 clarity and productivity benefits associated with the APL notation.
 
\end_layout

\begin_layout Section
Future Work
\end_layout

\begin_layout Standard
One of the most obvious questions to answer in future work is the performance
 potential of the specialized convolution functions against our naïve implementa
tion when using the same backend in Co-dfns; initial tests showed worse
 results and were omitted here.
 
\end_layout

\begin_layout Standard
There are a number of design elements of the current crop of APL implementations
, including Co-dfns, which hamper performance for machine learning.
 Especially, the use of 64-bit floating points without any feature to reduce
 their size makes memory usage a concern.
 Additionally, no optimization on the design of stencil has been done, while
 optimizations related to lazy indexing, batch processing, and a number
 of other features seem readily accessible.
 
\end_layout

\begin_layout Standard
Additionally, we would like to explore the potential of using such systems
 to improve machine learning pedagogy by encouraging students to have access
 to high-performance, but also transparent, implementations of foundational
 machine learning concepts.
 There are still some challenges to recommending this approach at scale
 for a large number of educational institutions, but we believe work on
 understanding the pedagogical benefits of APL warrants further research
 in addition to exploring APL in the professional space.
 
\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard
Given the notational advantages of APL and the concision and clarity of
 expression that one can obtain, we explored the potential impact of using
 APL as a language for implementing convolutional neural networks of reasonable
 complexity.
 We found that, though the traditional implementations of APL suffer from
 performance issues that would prevent widespread use in either academic,
 educational, or industrial contexts, compilers such as Co-dfns are capable
 of compiling complete neural network programs (in our case, the U-net architect
ure) and producing much more competitive performance results (within a factor
 of 2.2 - 2.4 times of our reference PyTorch implementation).
 This is despite the naïve nature of our implementation and the naïve optimizati
on support for neural networks on the part of the Co-dfns compiler.
 
\end_layout

\begin_layout Standard
Furthermore, we found that our effort to implement U-net in APL resulted
 in a concise but fully unambiguous and completely transparent implementation,
 without any frameworks or library dependencies.
 Despite being a complete 
\begin_inset Quotes eld
\end_inset

by hand
\begin_inset Quotes erd
\end_inset

 implementation, its complexity of expression is on par with that of PyTorch
 and other specialized frameworks, or even better, particularly in cases
 where more exploration and novel implementation is required, or when customized
 integrations may be called for.
 The insights that we gained from implementing U-net in APL affected our
 implementation of a reference implementation in PyTorch directly, suggesting
 that APL may have significant pedagogical advantages for teaching neural
 network programming and machine learning in general.
\end_layout

\begin_layout Section
\start_of_appendix
Complete APL U-Net Implementation
\end_layout

\begin_layout Verbatim

W←⍬ ⋄ V←⍬ ⋄ Z←⍬ ⋄ LR←1e¯9 ⋄ MO←0.99
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

FWD←{Z⊢←(≢W)⍴⊂⍬
\end_layout

\begin_layout Verbatim

 CV←{Z[⍺]←⊂⍵
\end_layout

\begin_layout Verbatim

  z←(,[2+⍳3]3 3⌺⍺⊃Z)+.×,[⍳3]⍺⊃W
\end_layout

\begin_layout Verbatim

  0⌈z⊣Z[⍺]←⊂Z[⍺],⊂z}
\end_layout

\begin_layout Verbatim

 CC←{p←2÷⍨(⍴⍺⊃Z)-⍴⍵
\end_layout

\begin_layout Verbatim

  ⍵,⍨(⌊p)↓(-⌈p)↓(⍺⊃Z)}
\end_layout

\begin_layout Verbatim

 MX←{⌈⌿[2],[2 3](2 2⍴2)⌺⊃Z[⍺]←⊂⍵}
\end_layout

\begin_layout Verbatim

 UP←{Z[⍺]←⊂⍵
\end_layout

\begin_layout Verbatim

  s←(2×¯1↓⍴⍵),¯1↑⍴⍺⊃W
\end_layout

\begin_layout Verbatim

  s⍴0 2 1 3 4⍉⍵+.×⍺⊃W}
\end_layout

\begin_layout Verbatim

 C1←{Z[⍺]←⊂⍵
\end_layout

\begin_layout Verbatim

  1E¯8+z÷[⍳2]+/z←*z-[⍳2]⌈/z←⍵+.×⍺⊃W}
\end_layout

\begin_layout Verbatim

 LA←{⍺≥≢Z:⍵
\end_layout

\begin_layout Verbatim

  down←(⍺+6)∇(⍺+2)MX(⍺+1)CV(⍺+0)CV ⍵
\end_layout

\begin_layout Verbatim

  (⍺+2)CC(⍺+5)UP(⍺+4)CV(⍺+3)CV down}
\end_layout

\begin_layout Verbatim

 2 C1 1 CV 0 CV 3 LA ⍵⍴⍨3↑1,⍨⍴⍵}
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

BCK←{Y←⍺ ⋄ Y∆←⍵
\end_layout

\begin_layout Verbatim

 ∆←{V[⍺]←⊂⍵+MO×(⍴⍵)⍴⍺⊃V
\end_layout

\begin_layout Verbatim

  W[⍺]←⊂(⍺⊃W)-LR×⍺⊃V}
\end_layout

\begin_layout Verbatim

 ∆CV←{w←,[⍳3]⊖⌽[1]0 1 3 2⍉⍺⊃W ⋄ x←⊃⍺⊃Z
\end_layout

\begin_layout Verbatim

  ∆z←⍵×0<1⊃⍺⊃Z
\end_layout

\begin_layout Verbatim

  ∆Z←¯2⊖¯2⌽[1](4+2↑⍴∆z)↑∆z
\end_layout

\begin_layout Verbatim

  _←⍺ ∆ 3 0 1 2⍉(⍉,[⍳2]∆z)+.×,[⍳2]3 3⌺x
\end_layout

\begin_layout Verbatim

  w+.×⍨,[2+⍳3]3 3⌺∆Z}
\end_layout

\begin_layout Verbatim

 ∆CC←{x←⍺⊃Z ⋄ ∆z←⍵ ⋄ d←-⌊2÷⍨2↑(⍴x)-⍴∆z
\end_layout

\begin_layout Verbatim

  (⊃d)⊖(1⊃d)⌽[1](⍴x)↑∆z}
\end_layout

\begin_layout Verbatim

 ∆MX←{x←⍺⊃Z ⋄ ∆z←⍵
\end_layout

\begin_layout Verbatim

  y×x=y←(⍴x)↑2⌿2/[1]∆z}
\end_layout

\begin_layout Verbatim

 ∆UP←{w←⍺⊃W ⋄ x←⍺⊃Z ⋄ ∆z←⍵
\end_layout

\begin_layout Verbatim

  _←⍺ ∆(⍉,[⍳2]x)+.×,[⍳2]cz←(2 2⍴2)⌺∆z
\end_layout

\begin_layout Verbatim

  (,[2+⍳3]cz)+.×⍉⍪w}
\end_layout

\begin_layout Verbatim

 ∆C1←{w←⍺⊃W ⋄ x←⍺⊃Z ⋄ ∆z←⍵
\end_layout

\begin_layout Verbatim

  _←⍺ ∆(⍉,[⍳2]x)+.×,[⍳2]∆z
\end_layout

\begin_layout Verbatim

  ∆z+.×⍉w}
\end_layout

\begin_layout Verbatim

 ∆LA←{⍺≥≢Z:⍵ ⋄ in←⍵↑[2]⍨-2÷⍨⊃⌽⍴⍵
\end_layout

\begin_layout Verbatim

  d←(⍺+6)∇(⍺+3)∆CV(⍺+4)∆CV(⍺+5)∆UP in
\end_layout

\begin_layout Verbatim

  (⍺+0)∆CV(⍺+1)∆CV(⍵ ∆CC⍨⍺+2)+(⍺+2)∆MX d
\end_layout

\begin_layout Verbatim

 }
\end_layout

\begin_layout Verbatim

 3 ∆LA 0 ∆CV 1 ∆CV 2 ∆C1 Y∆-(~Y),[1.5]Y}
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

E←{-+⌿,⍟(⍺×⍵[;;1])+(~⍺)×⍵[;;0]}
\end_layout

\begin_layout Verbatim

RUN←{Y←⌊0.5+nm↑⍵↓⍨2÷⍨(⍴⍵)-nm←2↑⍴Y∆←FWD ⍺
\end_layout

\begin_layout Verbatim

 Y Y∆(Y E Y∆)⊣Y BCK Y∆}
\end_layout

\begin_layout Section
PyTorch Reference Implementation
\end_layout

\begin_layout Verbatim

import torch
\end_layout

\begin_layout Verbatim

import torch.nn as nn
\end_layout

\begin_layout Verbatim

import torchvision
\end_layout

\begin_layout Verbatim

import torchvision.transforms.functional
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

class TwoConv(nn.Module):
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

 def __init__(
\end_layout

\begin_layout Verbatim

   self, in_channels, out_channels):
\end_layout

\begin_layout Verbatim

  super().__init__()
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

  self.path = nn.Sequential(
\end_layout

\begin_layout Verbatim

   nn.Conv2d(in_channels, out_channels, 
\end_layout

\begin_layout Verbatim

    kernel_size=(3, 3), bias=False),
\end_layout

\begin_layout Verbatim

    nn.ReLU(inplace=True),
\end_layout

\begin_layout Verbatim

    nn.Conv2d(
\end_layout

\begin_layout Verbatim

     out_channels, out_channels, 
\end_layout

\begin_layout Verbatim

     kernel_size=(3, 3), bias=False),
\end_layout

\begin_layout Verbatim

     nn.ReLU(inplace=True),
\end_layout

\begin_layout Verbatim

    )
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

 def forward(self, x):
\end_layout

\begin_layout Verbatim

  return self.path(x)
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

class Down(nn.Module):
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

 def __init__(self, in_channels):
\end_layout

\begin_layout Verbatim

  super().__init__()
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

  self.path = nn.Sequential(
\end_layout

\begin_layout Verbatim

   nn.MaxPool2d(
\end_layout

\begin_layout Verbatim

    kernel_size=(2, 2), stride=2),
\end_layout

\begin_layout Verbatim

    TwoConv(
\end_layout

\begin_layout Verbatim

     in_channels, 2 * in_channels
\end_layout

\begin_layout Verbatim

    ),
\end_layout

\begin_layout Verbatim

   )
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

 def forward(self, x):
\end_layout

\begin_layout Verbatim

  return self.path(x)
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

class Up(nn.Module):
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

 def __init__(self, in_channels):
\end_layout

\begin_layout Verbatim

  super().__init__()
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

  self.upsampling = nn.ConvTranspose2d(
\end_layout

\begin_layout Verbatim

   in_channels,
\end_layout

\begin_layout Verbatim

   in_channels // 2,
\end_layout

\begin_layout Verbatim

   kernel_size=(2, 2),
\end_layout

\begin_layout Verbatim

   stride=2,
\end_layout

\begin_layout Verbatim

   bias=False,
\end_layout

\begin_layout Verbatim

  )
\end_layout

\begin_layout Verbatim

  self.convolutions = 
\end_layout

\begin_layout Verbatim

   TwoConv(
\end_layout

\begin_layout Verbatim

    in_channels, in_channels // 2
\end_layout

\begin_layout Verbatim

   )
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

 def forward(self, x_to_crop, x_in):
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

  upped = self.upsampling(x_in)
\end_layout

\begin_layout Verbatim

  cropped = 
\end_layout

\begin_layout Verbatim

   torchvision.transforms.
\end_layout

\begin_layout Verbatim

    functional.center_crop(
\end_layout

\begin_layout Verbatim

     x_to_crop, upped.shape[-2:]
\end_layout

\begin_layout Verbatim

    )
\end_layout

\begin_layout Verbatim

  x = torch.cat([cropped, upped], dim=1)
\end_layout

\begin_layout Verbatim

  return self.convolutions(x)
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

class USegment(nn.Module):
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

 def __init__(
\end_layout

\begin_layout Verbatim

   self, in_channels, bottom_u=None
\end_layout

\begin_layout Verbatim

  ):
\end_layout

\begin_layout Verbatim

  super().__init__()
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

  if bottom_u is None:
\end_layout

\begin_layout Verbatim

   bottom_u = lambda x: x
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

  self.down = Down(in_channels)
\end_layout

\begin_layout Verbatim

  self.bottom_u = bottom_u
\end_layout

\begin_layout Verbatim

  self.up = Up(2 * in_channels)
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

 def forward(self, x):
\end_layout

\begin_layout Verbatim

  return self.up(
\end_layout

\begin_layout Verbatim

   x, self.bottom_u(self.down(x))
\end_layout

\begin_layout Verbatim

  )
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

class UNet(nn.Module):
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

 def __init__(self):
\end_layout

\begin_layout Verbatim

  super().__init__()
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

  self.u = USegment(512)
\end_layout

\begin_layout Verbatim

  self.u = USegment(256, self.u)
\end_layout

\begin_layout Verbatim

  self.u = USegment(128, self.u)
\end_layout

\begin_layout Verbatim

  self.u = USegment(64, self.u)
\end_layout

\begin_layout Verbatim

  self.path = nn.Sequential(
\end_layout

\begin_layout Verbatim

   TwoConv(1, 64),
\end_layout

\begin_layout Verbatim

   self.u,
\end_layout

\begin_layout Verbatim

   nn.Conv2d(
\end_layout

\begin_layout Verbatim

    64, 2, kernel_size=1, bias=False
\end_layout

\begin_layout Verbatim

   ),
\end_layout

\begin_layout Verbatim

  )
\end_layout

\begin_layout Verbatim

\end_layout

\begin_layout Verbatim

 def forward(self, x):
\end_layout

\begin_layout Verbatim

  return self.path(x)
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
balance
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "bibliography"
options "ACM-Reference-Format"

\end_inset


\end_layout

\end_body
\end_document
